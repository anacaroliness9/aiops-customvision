{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\r\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\r\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region\r\n",
    "from msrest.authentication import ApiKeyCredentials\r\n",
    "import time\r\n",
    "from sklearn import metrics\r\n",
    "import requests\r\n",
    "import os\r\n",
    "import yaml\r\n",
    "import json\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import itertools\r\n",
    "import time\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "import requests, pprint\r\n",
    "import uuid"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lab 2 - Continuous Learning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 1: Load configs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "%run ..\\Utils\\utils.py\r\n",
    "%run ..\\Utils\\utils-cv.py"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "config = load_configs(os.path.join(\"Config\", \"config.yaml\"))\r\n",
    "\r\n",
    "train_endpoint = config['cv']['TrainingEndpoint']\r\n",
    "training_key = config['cv']['TrainingKey']\r\n",
    "pred_endpoint = config['cv']['PredictionEndpoint']\r\n",
    "prediction_key = config['cv']['PredictionKey']\r\n",
    "prediction_resource_id = \"/subscriptions/8d47f388-3a7a-4970-9dec-2c6cc53e02a9/resourceGroups/rg_chihuahua_muffin/providers/Microsoft.CognitiveServices/accounts/cmcustomvision-prediction\"\r\n",
    "project_name = config['cv']['ProjectName']\r\n",
    "project_id = config['cv']['ProjectID']\r\n",
    "threshold = config['cv']['Threshold']\r\n",
    "path_training_images = os.path.join(get_project_dir(), \"Deploy\", \"training-images\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Authenticate the client"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "cv = CustomVisionProject()\r\n",
    "trainer = cv.get_trainer(training_key, train_endpoint)\r\n",
    "predictor = cv.get_predictor(prediction_key, pred_endpoint)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "##\r\n",
    "cv.get_project(project_id)\r\n",
    "print(cv.project.id)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8217f4df-bf35-4e9a-8dfc-6a5e18b4d1a5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "cv.project.name"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'fruit-classifier-gerdau'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2: Getting images received by the endpoint\r\n",
    "\r\n",
    "In the Custon Vision portal, is the images from **Predictions** tab."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# Printar as tags que o modelo previu atravÃ©s do endpoint \r\n",
    "#limite de duas queries por vez\r\n",
    "tags_ids = [t['id'] for t in trainer.get_tags(project_id, raw=True).response.json()]\r\n",
    "queries = []\r\n",
    "query_pred_bytags = {}\r\n",
    "query_pred_bytags['tags'] = []\r\n",
    "coringa = []\r\n",
    "\r\n",
    "for i in tags_ids:\r\n",
    "    tags = []\r\n",
    "    tags.append({\"id\" : i, \"minThreshold\" : 0.1})\r\n",
    "    queries.append({\"tags\" : tags } )\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "#creating query to get the images received by the endpoint\r\n",
    "batch_img_tags = {}\r\n",
    "batch_img_tags[\"images\"] = []\r\n",
    "for i in queries:\r\n",
    "    predicted_imgs = trainer.query_predictions(project_id, query=i, raw=True).response.json()\r\n",
    "    for r in predicted_imgs[\"results\"]:\r\n",
    "        batch_img_tags[\"images\"].append({ \"id\" : r[\"id\"], \"tagId\" : r[\"predictions\"][0][\"tagId\"] })"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "print(json.dumps(batch_img_tags, indent=2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\n",
      "  \"images\": [\n",
      "    {\n",
      "      \"id\": \"61f2de46-e32e-49fb-85f7-e8481933ee51\",\n",
      "      \"tagId\": \"c9d388dc-cd14-4b0c-b35e-858a84ce75db\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"a9e74e16-6075-4fa8-a521-264ab0dfab24\",\n",
      "      \"tagId\": \"3bc16af9-9c12-4dea-846a-ad33206c3307\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"0c8b99f5-21ac-4a7c-bbcf-6caae71fafb9\",\n",
      "      \"tagId\": \"8bcf4dc4-ae2b-47f5-9315-aecf4c88cc3a\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"3f26fc10-c7e1-4cc6-afeb-de62040aec96\",\n",
      "      \"tagId\": \"8bcf4dc4-ae2b-47f5-9315-aecf4c88cc3a\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3: Send the images from **Predictions** to **Training Images**\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# send the images received by the endpoit to the Training Images\r\n",
    "def create_image_from_predictions_rest(documents):\r\n",
    "    ''' Endpoints: entities, sentiment, languages, keyPhrases'''\r\n",
    "\r\n",
    "    #endpoint = train_endpoint + 'customvision/v3.3/training/projects/{}/images/tags'.format(project.id)\r\n",
    "    endpoint = 'https://eastus.api.cognitive.microsoft.com' + '/customvision/v3.3/Training/projects/{}/images/predictions'.format(project_id)\r\n",
    "    #print(project_id)\r\n",
    "    #print(endpoint)\r\n",
    "    # Setup the header information for the REST request passing in the subscription key\r\n",
    "    headers = {\"Training-key\": training_key, \"Content-Type\" : \"application/json\"}\r\n",
    "    #print(training_key)\r\n",
    "    # Build the REST request by passing in the complete URL, header information for authentication, and the JSON document\r\n",
    "    response = requests.post(endpoint, headers=headers, json=documents)\r\n",
    "\r\n",
    "    # Create a variable to store the results that are returned from the REST request\r\n",
    "    entities = response.json()\r\n",
    "\r\n",
    "    # Output the result using pprint.\r\n",
    "    #print(entities)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "create_image_from_predictions_rest(batch_img_tags)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# get untagged images\r\n",
    "print(len(cv.get_untagged_imgs()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 4: Filter only the images with the threshold above the expected and tagg them\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "threshold"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "#Filter just images with predictions more than the threshold defined to generate the query to tag them\r\n",
    "untagged_img = [i.id  for i in trainer.get_untagged_images(cv.project.id)]\r\n",
    "\r\n",
    "sugg =trainer.suggest_tags_and_regions(cv.project.id, cv.get_iteration_id(), untagged_img, raw = True).response.json()\r\n",
    "batch_img_tags = {}\r\n",
    "batch_img_tags[\"tags\"] = []\r\n",
    "for r in sugg:\r\n",
    "    #print(r)\r\n",
    "    if (r[\"predictions\"][0][\"probability\"] > threshold):\r\n",
    "        batch_img_tags[\"tags\"].append({ \"imageId\" : r[\"id\"], \r\n",
    "                                        \"tagId\" : r[\"predictions\"][0][\"tagId\"]})\r\n",
    "len(batch_img_tags[\"tags\"])                                        "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "print(json.dumps(batch_img_tags, indent=2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\n",
      "  \"tags\": [\n",
      "    {\n",
      "      \"imageId\": \"a5bccf0f-deea-47eb-b893-e54a27b0a824\",\n",
      "      \"tagId\": \"8bcf4dc4-ae2b-47f5-9315-aecf4c88cc3a\"\n",
      "    },\n",
      "    {\n",
      "      \"imageId\": \"5e423a94-124f-496d-a2df-452a46fe154e\",\n",
      "      \"tagId\": \"3bc16af9-9c12-4dea-846a-ad33206c3307\"\n",
      "    },\n",
      "    {\n",
      "      \"imageId\": \"abd18af1-e585-430c-9c69-32d583132aac\",\n",
      "      \"tagId\": \"c9d388dc-cd14-4b0c-b35e-858a84ce75db\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "# o metodo da sdk trainer.create_image_tags nÃ£o estÃ¡ funcionando\r\n",
    "import requests, pprint\r\n",
    "\r\n",
    "def create_image_tags_rest(documents):\r\n",
    "    ''' Endpoints: entities, sentiment, languages, keyPhrases'''\r\n",
    "\r\n",
    "    #endpoint = train_endpoint + 'customvision/v3.3/training/projects/{}/images/tags'.format(project.id)\r\n",
    "    endpoint = 'https://eastus.api.cognitive.microsoft.com' + '/customvision/v3.3/Training/projects/{}/images/tags'.format(cv.project.id)\r\n",
    "    print(project_id)\r\n",
    "    print(endpoint)\r\n",
    "    # Setup the header information for the REST request passing in the subscription key\r\n",
    "    headers = {\"Training-key\": training_key, \"Content-Type\" : \"application/json\"}\r\n",
    "    print(training_key)\r\n",
    "    # Build the REST request by passing in the complete URL, header information for authentication, and the JSON document\r\n",
    "    response = requests.post(endpoint, headers=headers, json=documents)\r\n",
    "\r\n",
    "    # Create a variable to store the results that are returned from the REST request\r\n",
    "    entities = response.json()\r\n",
    "\r\n",
    "    # Output the result using pprint.\r\n",
    "    print(entities)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "create_image_tags_rest(batch_img_tags)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8217f4df-bf35-4e9a-8dfc-6a5e18b4d1a5\n",
      "https://eastus.api.cognitive.microsoft.com/customvision/v3.3/Training/projects/8217f4df-bf35-4e9a-8dfc-6a5e18b4d1a5/images/tags\n",
      "8b5460f998a74816ad0f4d5c662defa7\n",
      "{'created': [{'imageId': 'abd18af1-e585-430c-9c69-32d583132aac', 'tagId': 'c9d388dc-cd14-4b0c-b35e-858a84ce75db'}, {'imageId': '5e423a94-124f-496d-a2df-452a46fe154e', 'tagId': '3bc16af9-9c12-4dea-846a-ad33206c3307'}, {'imageId': 'a5bccf0f-deea-47eb-b893-e54a27b0a824', 'tagId': '8bcf4dc4-ae2b-47f5-9315-aecf4c88cc3a'}], 'duplicated': [], 'exceeded': []}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "# get untagged images\r\n",
    "print(len(cv.get_untagged_imgs()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now tag the leftover image at custom vision portal and upload at least 15 images (but remember the recommended is at least 50 per tag to ensure performance)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "cv.upload_local_images(os.path.join(project_path(),'Deploy', 'new-tags'), ['caju'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Uploading images...\n",
      "Uploading 'caju' images:\n",
      "Image 38494331000-9c35c44ce0-5k.jpg sucessfully uploaded!\n",
      "Image 58bd0787ab596f4286730bacc710231e.jpg sucessfully uploaded!\n",
      "Image caju-2-1200x738-1.jpg sucessfully uploaded!\n",
      "Image caju-7.png sucessfully uploaded!\n",
      "Image caju-thumb11400223.jpg sucessfully uploaded!\n",
      "Image caju11-203829d000569330bb15897565181320-640-0.jpg sucessfully uploaded!\n",
      "Image depositphotos_54896479-stock-photo-brazilian-caju-cashew-fruit.jpg sucessfully uploaded!\n",
      "Image download.htm sucessfully uploaded!\n",
      "Image D_NQ_NP_968734-MLB31610550130_072019-O.jpg sucessfully uploaded!\n",
      "Image f131519cc9c5dd1e06c207237cab3b4f.jpg sucessfully uploaded!\n",
      "Image fruta-decorativa-caju-frutas-decorativas.jpg sucessfully uploaded!\n",
      "Image images.jfif sucessfully uploaded!\n",
      "Image img1.jfif sucessfully uploaded!\n",
      "Image img2.jfif sucessfully uploaded!\n",
      "Image img3.jpg sucessfully uploaded!\n",
      "Image img4.jpg sucessfully uploaded!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 5: Re-train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "cv.train_model()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Training ...\n",
      "Completed ...\n",
      "Model trained!\n",
      "Iteration id: 5d580275-6166-41cf-bf5a-c1cfe0a9ec7e\n",
      "Iteration name: Iteration 2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 6: Publish the new iteration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "publish_iteration_name = str(uuid.uuid1())\r\n",
    "cv.trainer.publish_iteration(project_id, cv.get_iteration_id(), publish_iteration_name, prediction_resource_id)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "# Classify test images\r\n",
    "test_img_dir = os.path.join(project_path(),'Deploy','test-images')\r\n",
    "image = 'IMG_TEST_4.JPG'\r\n",
    "\r\n",
    "image_data = open(os.path.join(test_img_dir,image), \"rb\").read()\r\n",
    "result = (cv.predictor.classify_image(project_id, cv.get_iteration_publis_name(), image_data))\r\n",
    "print(image, ': {} ({:.0%})'.format(result.predictions[0].tag_name, result.predictions[0].probability))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "IMG_TEST_4.JPG : caju (100%)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "img_url = 'https://th.bing.com/th/id/OIP.1tq1RrlV1TnjuP4eNx9pcAHaE8?pid=ImgDet&rs=1'\r\n",
    "result = (cv.predictor.classify_image_url(project_id, publish_iteration_name, img_url ))\r\n",
    "print(img_url, ': {} ({:.0%})'.format(result.predictions[0].tag_name, result.predictions[0].probability))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://th.bing.com/th/id/OIP.1tq1RrlV1TnjuP4eNx9pcAHaE8?pid=ImgDet&rs=1 : caju (98%)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "\r\n",
    "img_url = 'https://th.bing.com/th/id/R.d21316cc72adbdc748c915094a063173?rik=H50nE3XeVuxm%2bQ&riu=http%3a%2f%2fstreetsmartbrazil.files.wordpress.com%2f2008%2f12%2fcaju.jpg&ehk=62O4h64%2bU43NDKdzUf8uMk1qZJJOufCoL%2byM9WhreYw%3d&risl=&pid=ImgRaw&r=0'\r\n",
    "result = (cv.predictor.classify_image_url(project_id, publish_iteration_name, img_url ))\r\n",
    "print(img_url, ': {} ({:.0%})'.format(result.predictions[0].tag_name, result.predictions[0].probability))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://th.bing.com/th/id/R.d21316cc72adbdc748c915094a063173?rik=H50nE3XeVuxm%2bQ&riu=http%3a%2f%2fstreetsmartbrazil.files.wordpress.com%2f2008%2f12%2fcaju.jpg&ehk=62O4h64%2bU43NDKdzUf8uMk1qZJJOufCoL%2byM9WhreYw%3d&risl=&pid=ImgRaw&r=0 : caju (100%)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "ae3aa6c730e1edb1dd98cf035d1e9499e7ec05eacdf7289be61cfcb5b0ba0660"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}